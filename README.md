# AI Answer Evaluation for Sustainable AI Systems ğŸŒ±

## ğŸ“˜ Overview
This project focuses on developing an **AI Answer Evaluation system** that can automatically assess the correctness, relevance, and sustainability impact of AI-generated responses.  
It aims to support **responsible and efficient AI usage** by reducing manual evaluation effort and ensuring AI systems produce reliable, unbiased, and energy-efficient answers.

---

## ğŸ¯ Objectives
- Automate evaluation of AI-generated answers using NLP-based techniques.
- Promote sustainable and ethical AI development.
- Reduce human effort and time in response validation.
- Build a foundation for AI models that align with responsible computing goals.

---

## âš™ï¸ Technologies Used
- Python ğŸ  
- NLP Libraries (Transformers, NLTK, Scikit-learn)  
- Pandas / NumPy  
- Google Colab / Jupyter Notebook

---

## ğŸ“‚ Repository Structure
```
WEEK1/
â”‚
â”œâ”€â”€ problem_statement.txt
â”œâ”€â”€ objectives.txt
â”œâ”€â”€ methodology.txt
â”œâ”€â”€ expected_outcomes.txt
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Week 1 Milestone
**Improvisations done:**
- Refined problem statement to focus on sustainable AI evaluation.
- Identified suitable NLP tools for automated answer checking.
- Created a clear project documentation structure.

**GitHub Repository Link:**  
ğŸ‘‰ [https://github.com/Dharshin1/Ai-Answer-Evaluation](https://github.com/Dharshin1/Ai-Answer-Evaluation)
